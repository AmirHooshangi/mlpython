TODO:

- write tutorial
- add in documentation that deepcopy should be used to copy the iterated elements of an mlproblem
  (think of example where the underlying mlproblem always yields the same container or nparray
  but changes its content)
  HUGO: NO! Using a container is a very bad idea! It doesn't work well with zip(...), which doesn't do a deep copy!
- figure out a way to fascilitate the compilation of mathutils (i.e. without having to edit the setup.py file)
- figure out a way to allow for having compiled mathutils for different platforms at the same time
- figure out a way to include other people's software (add a directory in learners, 
  which give all the info/code for downloading other people's software, installing it and
  incorporating it to the library)
- dynamic module should be sequential, and should be a directory (for unsup. and sup. sequential problems)
- add the simple learners (nnet, ranking learners, etc.) that I already have
- might want to consider adding a 'n_fields' option. See "has_single_field" option of MinibatchProblem to understand why...
- once the documentation is done, should go back and add some cross references
- add ranking to datasets.store, with support for Yahoo Ranking Challenge Dataset
- add FreeBSD license to library
- add useful links to documnetation for ml in python, in general
  * profiling, e.g. http://packages.python.org/line_profiler/
  * C programming within Numpy
  * Python speed performance tips: http://wiki.python.org/moin/PythonSpeed/PerformanceTips#Avoidingdots...
- figure out get_problem(), for Toronto face dataset (see code!), yahoo_ltrc, 
  mnist, icml2007, and more...
- add tools for generating/viewing results (k-fold, early-stopping, save results, viewing results in tables or plots)
- figure out a way of having test suites
- for datasets:
  * need to add the option of asking for a fold, by adding a ``fold``Â option to get_*_problem. 
    By default it would be None, and it would only work for datasets that support it.
  * might want to make sure that the dtype of the data is the same when it is read from the file and
    and when it is in memory
  * could add support for extra arguments using **kwargs, which can be used to pass arbitrary keywords.
    This could have some unwanted effect, so perhaps I would need to be careful. Here's an example of how
    useful this can be (see http://www.saltycrane.com/blog/2008/01/how-to-use-args-and-kwargs-in-python/ for more):

     >>> def f(x,**kwargs):
     ...    return g(x,**kwargs)
     ... 
     >>> def g(x,blu=0,bla=0):
     ...    return x+blu+bla/2.
     ... 
     >>> f(1,blu=10,bla=20)
     21.0
     >>> f(1,bla=10,blu=20)
     26.0

