#! /usr/bin/python

# Copyright 2011 David Brouillard & Guillaume Roy-Fontaine. All rights reserved.
# 
# Redistribution and use in source and binary forms, with or without modification, are
# permitted provided that the following conditions are met:
# 
#    1. Redistributions of source code must retain the above copyright notice, this list of
#       conditions and the following disclaimer.
# 
#    2. Redistributions in binary form must reproduce the above copyright notice, this list
#       of conditions and the following disclaimer in the documentation and/or other materials
#       provided with the distribution.
# 
# THIS SOFTWARE IS PROVIDED BY David Brouillard & Guillaume Roy-Fontaine ``AS IS'' AND ANY EXPRESS OR IMPLIED
# WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
# FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL David Brouillard & Guillaume Roy-Fontaine OR
# CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
# SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
# ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
# NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF
# ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
# 
# The views and conclusions contained in the software and documentation are those of the
# authors and should not be interpreted as representing official policies, either expressed
# or implied, of David Brouillard & Guillaume Roy-Fontaine.


# ex: python create_experiment_script TASK=classification DATASET=heart MODULE=mlpython.learners.third_party.milk.classification LEARNER=TreeClassifier RESULTS_FILE=result_file min_split criterion > script.py
# To execute the generated script: python script.py 3 \'information_gain\'


# Early_Stopping ex : python create_experiment_script TASK=classification DATASET=heart MODULE=mlpython.learners.third_party.milk.classification LEARNER=TreeClassifier RESULTS_FILE=result_file EARLY_STOPPING=n_stage BEG=1 INCR=2 END=500 LOOK_AHEAD=10 min_split criterion > script.py



# (y)TODO: Verifier l'integralite des commentaires
# (y)TODO: Commentaire en anglais
# (y)TODO: Parametre optionnel et +
# (y)TODO: Verification des options parent par rapport au script enfant
# (y)TODO: L'ordre des params n'est pas gerer dans le script enfant pour le print dans le result_file
# (y)TODO: Gerer les tests retournant plus qu'un cost (pour le  result_file?)
# (y)TODO: Gerer EARLY_STOPPING param et ses param a lui
# (y)TODO: Gerer EARLY_STOPPING dans le script enfant
# TODO: Dans une doc, expliquer que les quotes donc etre passee avec backslash


import os
import sys
from string import Template

if (len(sys.argv) >= 6):    
    arguments = sys.argv
    arguments.pop(0);	# Remove first argument

    # Parsing Keywords
    splitedArguments = []
    options = []
    for item in arguments:
        if item.find('=') == -1:
            options.append(item) # Option(s)
        else:
            splitedArguments.append(item.partition('=')) # Main's parameters with '=' in it
    
	dict_Arguments = {} # Create a dictionary that will be used to substitute the template
	for item in splitedArguments:
		dict_Arguments[item[0]] = item[2]

    # Verify if all the required param are provived
    requiredParam = 0
    raiseRequiredError = 0
    if 'TASK' in dict_Arguments:
        requiredParam += 1
    else:
        raiseRequiredError = 1
    if 'MODULE' in dict_Arguments:
        requiredParam += 1
    else:
        raiseRequiredError = 1
    if 'LEARNER' in dict_Arguments:
        requiredParam += 1
    else:
        raiseRequiredError = 1
    if 'RESULTS_FILE' in dict_Arguments:
        requiredParam += 1
    else:
        raiseRequiredError = 1
    if 'DATASET' in dict_Arguments:
        requiredParam += 1
    else:
        raiseRequiredError = 1
                
    if raiseRequiredError == 1:
        raise ValueError('There should be at least 5 parameters required. \'TASK\', \'DATASET\', \'MODULE\', \'LEARNER\' and \'RESULTS_FILE\'')
      
            
    # Verify if the param 'EARLY_STOPPING is provided
    earlyStoppingParam = 0
    if 'EARLY_STOPPING' in dict_Arguments:
        # Verify if each of the 'EARLY_STOPPING' param are provided : 'BEG', 'INCR', 'END', 'LOOK_AHEAD'
        raiseEarlyStoppingError = 0
        if 'BEG' in dict_Arguments:
            earlyStoppingParam += 1
        else:
            raiseEarlyStoppingError = 1
        if 'INCR' in dict_Arguments:
            earlyStoppingParam += 1
        else:
            raiseEarlyStoppingError = 1
        if 'END' in dict_Arguments:
            earlyStoppingParam += 1
        else:
            raiseEarlyStoppingError = 1
        if 'LOOK_AHEAD' in dict_Arguments:
            earlyStoppingParam += 1
        else:
            raiseEarlyStoppingError = 1
        if 'EARLY_STOPPING_COST_ID' in dict_Arguments:
            early_stopping_cost_id = dict_Arguments['EARLY_STOPPING_COST_ID']
        else:
            early_stopping_cost_id = 0
                    
        if raiseEarlyStoppingError == 1:
            raise ValueError('There are 4 parameters required with the \'EARLY_STOPPING\' option. \'BEG\', \'INCR\', \'END\', \'LOOK_AHEAD\'')
         
                
    # Create a string that will be used in the child script to generate the header
    str_RequiredParam = "\'\'"
    if len(options) > 1:
        str_RequiredParam = "\'"
        for item in options:
            str_RequiredParam += item
            str_RequiredParam += "\\t"
    
        str_RequiredParam += "\'"
        
            
    # Substitute dictionary's keywords in the template
    result = 'import numpy as np\n'
    result += 'import os\n'
    result += 'import sys\n'
    result += 'import fcntl\n'
    result += 'import copy\n'
    result += 'from string import Template\n'
    result += 'import mlpython.datasets.store as dataset_store\n'
    result += Template('from $MODULE import ${LEARNER}\n\n').safe_substitute(dict_Arguments)
    result += Template('trainset,validset,testset = dataset_store.get_${TASK}_problem(\'${DATASET}\')\n\n').safe_substitute(dict_Arguments)
    result += 'str_ParamOption = ""\n'
    result += 'str_ParamOptionValue = ""\n'
    result += 'if (len(sys.argv) > 1):\n'
    result += '    requiredOptionFromParentScript = ' + str_RequiredParam + '\n\n'
    result += '    requiredOption = []\n'
    result += '    for item in requiredOptionFromParentScript.split("\\t"):\n'
    result += '        requiredOption.append(item)\n\n'
    result += '    requiredOption.remove("") # Remove empty string in the list\n\n' 
    result += '    arguments = sys.argv\n'
    result += '    arguments.pop(0);	# Remove first argument\n\n'
    result += '    splitedArguments = []\n'
    result += '    for item in arguments:\n'
    result += '        splitedArguments.append(item) # Option(s)\n\n'
    result += '    # Check if every option(s) from parent\'s script are here.\n'
    result += '    if ' + str(len(options)) + ' != len(splitedArguments):\n'
    result += '        exempleOption = ""\n'
    result += '        for item in requiredOption:\n'
    result += '            exempleOption += item \n'
    result += '            exempleOption += "=\'value\' "\n'
    result += '        raise ValueError(\'Parameter(s) must be in this order: \' + requiredOptionFromParentScript.replace("\\t", " ") + "\\nex: python script.py " + exempleOption + "\\n")\n'
    result += '    for index, item in enumerate(splitedArguments):\n'
    result += '        str_ParamOption += requiredOption[index]\n'
    result += '        str_ParamOption += \'=\' \n'
    result += '        str_ParamOption += item\n'
    result += '        if ((index+1) < len(splitedArguments)): # If not the last\n'
    result += '            str_ParamOptionValue += item+\'\\t\'\n'
    result += '            str_ParamOption += \', \'\n'
    result += '        else:\n'
    result += '            str_ParamOptionValue += item\n\n'
    result += Template('    objectString = \'myObject = ${LEARNER}(\' + str_ParamOption + \')\'\n\n').safe_substitute(dict_Arguments)
    result += '    print str_ParamOption\n'
    result += '    code = compile(objectString, \'<string>\', \'exec\')\n'
    result += '    exec code\n'
    result += 'else:\n'
    result += Template('    myObject = ${LEARNER}()\n\n').safe_substitute(dict_Arguments)

    if earlyStoppingParam == 4: # Early_Stopping
        result += '# Early_Stopping Code\n'
        result += 'best_val_error = np.inf\n'
        result += 'best_it = 0\n'
        result += Template('look_ahead = ${LOOK_AHEAD}\n').safe_substitute(dict_Arguments)
        result += 'n_incr_error = 0\n'
        result += Template('for stage in range(${BEG},${END}+1,${INCR}):\n').safe_substitute(dict_Arguments)
        result += '    if not n_incr_error < look_ahead:\n'
        result += '        break\n'
        result += Template('    myObject.${EARLY_STOPPING} = stage\n').safe_substitute(dict_Arguments)
        result += '    myObject.train(trainset)\n'
        result += '    n_incr_error += 1\n'
        result += '    print \'Evaluating on validation set\'\n'
        result += '    outputs, costs = myObject.test(validset)\n'
        result += '    error = np.mean(costs,axis=0)[' + str(early_stopping_cost_id) + ']\n'
        result += '    print \'Error: \' + str(error)\n'
        result += '    if error < best_val_error:\n'
        result += '        best_val_error = error\n'
        result += '        best_it = stage\n'
        result += '        n_incr_error = 0\n'
        result += '        best_model = copy.deepcopy(myObject)\n\n'
        result += 'outputs_tr,costs_tr = best_model.test(trainset)\n'
        result += 'columnCount = len(costs_tr.__iter__().next())\n'
        result += 'outputs_v,costs_v = best_model.test(validset)\n'
        result += 'outputs_t,costs_t = best_model.test(testset)\n\n'
    else:
        result += 'model = myObject.train(trainset)\n'
        result += 'outputs_tr,costs_tr = myObject.test(trainset)\n'
        result += 'columnCount = costs_tr.shape[1]\n'
        result += 'outputs_v,costs_v = myObject.test(validset)\n'
        result += 'outputs_t,costs_t = myObject.test(testset)\n\n'
    
    result += 'str_header = ""\n'
    result += 'str_modelinfo = ""\n'
    result += 'if columnCount > 1:\n'
    result += '    train = ""\n'
    result += '    valid = ""\n'
    result += '    test = ""\n\n'
    result += '    # Get average of each costs\n'
    result += '    for index in range(columnCount):\n'
    result += '        train = str(np.mean(costs_tr,axis=0)[index])\n'
    result += '        valid = str(np.mean(costs_v,axis=0)[index])\n'
    result += '        test = str(np.mean(costs_t,axis=0)[index])\n'
    result += '        str_header += \'train\' + str(index+1) + \'\\tvalid\' + str(index+1) + \'\\ttest\' + str(index+1)\n'
    result += '        str_modelinfo += train + \'\\t\' + valid + \'\\t\' + test\n'
    result += '    str_header += \'\\n\'\n'
    result += 'else:\n'
    result += '    str_header = \'train1\\tvalid1\\ttest1\\n\'\n\n'
    result += '    train_error = str(np.mean(costs_tr,axis=0)[0])\n'
    result += '    valid_error = str(np.mean(costs_v,axis=0)[0])\n'
    result += '    test_error = str(np.mean(costs_t,axis=0)[0])\n'
    result += '    str_modelinfo = train_error + \'\\t\' + valid_error + \'\\t\' + test_error\n\n'
    result += '# Preparing result file\n'
    result += 'header_line = ""\n'
    if len(options) > 1: # If more options was set
        result += 'header_line += ' + str_RequiredParam + '\n'
    result += 'header_line += str_header\n'
    result += Template('result_file = \'${RESULTS_FILE}\'\n\n').safe_substitute(dict_Arguments)
    result += 'if not os.path.exists(result_file):\n'
    result += '    f = open(result_file, \'w\')\n'
    result += '    f.write(header_line)\n'
    result += '    f.close()\n\n'
    result += '# Look if there is optional values to display\n'
    result += 'if str_ParamOptionValue == "":\n'
    result += '    model_info = [str_modelinfo]\n'
    result += 'else:\n'
    result += '    model_info = [str_ParamOptionValue,str_modelinfo]\n\n'
    result += 'line = \'\\t\'.join(model_info)+\'\\n\'\n'
    result += 'f = open(result_file, "a")\n'
    result += 'fcntl.flock(f.fileno(), fcntl.LOCK_EX)\n'
    result += 'f.write(line)\n'
    result += 'f.close() # unlocks the file\n'
    
    print result # Print result in a file (' > ' must be used)
else:
    # TODO: Do a better exemple for the different options of the script...
    print "You must provide at least 5 parameter"
    print "ex: python create_experiment_script TASK=classification DATASET=heart MODULE=mlpython.learners.third_party.milk.classification LEARNER=TreeClassifier RESULTS_FILE=result_file min_split criterion > script.py"


